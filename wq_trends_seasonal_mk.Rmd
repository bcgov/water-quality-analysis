---
title: "Trends in Water Quality in BC Rivers (DRAFT 1)"
author: "Andy Teucher"
date: "`r Sys.Date()`"
output: 
  pdf_document: 
    toc: yes
params: 
  refresh_data: FALSE
---

## Introduction

This presents draft initial results of seasonal Mann-Kendall trend tests on 
selected parameters at water quality monitoring stations from the 
Federal-Provincial water quality monitoring network.

```{r setup, include=FALSE}
library(canwqdata)
library(dplyr)
library(tidyr)
library(ggplot2)
library(forcats)
library(lubridate)
library(wqbc)
library(readr)
library(here)
library(feather)
library(EnvStats)
library(purrr)
library(kableExtra)
source(here::here("R/functions.R"))

knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
options(knitr.kable.NA = '')

options(wqbc.messages = FALSE)
```

```{r load, eval=params$refresh_data || !file.exists(here::here("data/bcdata.rds"))}
bc_stations <- wq_sites() %>% 
  filter(SITE_NO %in% wqbc::ems_ec_stations$envirodat_no)

bc_data <- wq_site_data(unique(bc_stations$SITE_NO)) %>% 
  left_join(select(bc_stations, SITE_NO, PEARSEDA), 
            by = "SITE_NO") %>% 
  distinct()

bc_data$VALUE_VALEUR[bc_data$VALUE_VALEUR < -900] <- NA

saveRDS(bc_data, here::here("data/bcdata.rds"))
saveRDS(bc_stations, here::here("data/bc_stations.rds"))
```


```{r EC-data-tidy}
# load data
bc_data <- readRDS(here::here("data/bcdata.rds"))
bc_stations <- readRDS(here::here("data/bc_stations.rds"))
# load parameters:
wq_params <- read_csv(here::here("data/parameters.csv"))

# TODO - check wq_params with very high CV - especially TEMPERATURE WATER vs 
# TEMPERATURE WATER (FIELD)

bc_tidy <- tidy_ec_data(bc_data, cols = "PEARSEDA", mdl_action = "mdl") %>% 
  add_shortnames() %>% 
  inner_join(wq_params %>% 
               select(Category, PARAM_SHORT_NAME = Variable_short_name)) %>% 
  filter(year(DateTime) > 2003) %>% 
  group_by(SITE_NO, PARAM_SHORT_NAME, DateTime, Units, DetectionLimit, 
           ResultLetter, PEARSEDA, Category) %>% 
  summarise(sd = sd(Value, na.rm = TRUE), 
            Value = mean(Value, na.rm = TRUE), 
            cv = (sd / Value) * 100,
            n = n()) %>% 
  ungroup() %>% 
  mutate(PARAM_SHORT_NAME = fct_reorder(PARAM_SHORT_NAME, as.numeric(as.factor(Category))),
         year = year(DateTime), 
         month = month(DateTime), 
         censored = make_censor(ResultLetter))

bc_site_var_summary <- bc_tidy %>% group_by(SITE_NO, PARAM_SHORT_NAME, Category) %>% 
  summarize(min_year = min(year, na.rm = TRUE), 
            max_year = max(year, na.rm = TRUE), 
            nyears = max_year - min_year + 1,
            n_obs = n(),
            n_cens = sum(censored != "none")) %>% 
  filter(max_year >= 2013, nyears >= 10) %>% 
  ungroup()

bc_tidy <- inner_join(bc_tidy, bc_site_var_summary, 
                      by = c("SITE_NO", "PARAM_SHORT_NAME", "Category"))

# TODO: trim ends of ts when very sparse data
```

A total of `r nrow(wq_params)` parameters were selected to be tested at all sites:

```{r}
kable(wq_params, booktabs = TRUE, longtable = TRUE, 
      caption = "List of parameters tested for trends") %>% 
  kable_styling(latex_options = c("striped", "repeat_header")) %>% 
  column_spec(3, width = "11em") %>% 
  column_spec(4, width = "14em")
```


```{r clean-make-monthly}

bc_nested <- tidyr::nest(bc_tidy, -PEARSEDA, -SITE_NO, -PARAM_SHORT_NAME, 
                         -Category, -min_year, -max_year, -nyears, -n_obs, -n_cens)

bc_nested <- bc_nested %>% mutate(
  clean_data = map(data, ~ {
    clean_wqdata(.x, 
                 delete_outliers = TRUE) %>% 
      mutate(censored = make_censor(ResultLetter), 
             month = month(Date, label = FALSE), 
             year = year(Date), 
             Time = as.numeric(Date) / 1000) %>% 
      arrange(Date)
  }), 
  n_outliers = map_int(clean_data, attr, "wq_n_outliers"),
  full_monthly = map(clean_data, month_complete)
)
```

```{r smk}
bc_nested <- mutate(
  bc_nested, 
  sk = map(full_monthly, ~ {
    kendallSeasonalTrendTest(.x$month_avg, season = .x$month, 
                                       year = .x$year)
  }), 
  annual_slope = map_dbl(sk, slope), 
  slope_p_val = map_dbl(sk, p_val), 
  sig = slope_p_val < 0.05,
  intercept = map2_dbl(full_monthly, annual_slope, 
                      ~ smk_int_from_data(.x, slope = .y)), 
  ## Convert to average annual percent change: 100 * (Yend/Ystart - 1) / n_years.
  ann_percent_change = 100 * 
    ((((annual_slope * nyears + intercept) / 
         intercept) - 1) / 
       nyears),
  slope_het_pval = map_dbl(sk, possibly(het_p_val, otherwise = NA_real_)),
  smk_plot = pmap(
   list(d = full_monthly, m = sk, s = SITE_NO,
        v = PARAM_SHORT_NAME), function(d, m, s, v) {
          plot_smk(d, m, "month_avg", "Date") +
            labs(title = paste(s, v, sep = ": "),
                 x = "Date", y = "Value")

        })
)
```

## Brief summary of results

Of the `r nrow(bc_nested)` tests performed, `r nrow(bc_nested[bc_nested$sig, ])` showed 
statistically significant trends. The parameter that showed signifcant decreases at the most sites
was `r names(which.max(table(bc_nested[bc_nested$sig & bc_nested$annual_slope < 0, "PARAM_SHORT_NAME"])))` (`r max(table(bc_nested[bc_nested$sig & bc_nested$annual_slope < 0, "PARAM_SHORT_NAME"]))` sites). The parameter that showed significant increases at the most sites
was `r names(which.max(table(bc_nested[bc_nested$sig & bc_nested$annual_slope > 0, "PARAM_SHORT_NAME"])))` (`r max(table(bc_nested[bc_nested$sig & bc_nested$annual_slope > 0, "PARAM_SHORT_NAME"]))` sites). The site with the highest number of parameters that showed statistically significant trends was `r names(which.max(table(bc_nested[bc_nested$sig, "SITE_NO"])))` (`r  max(table(bc_nested[bc_nested$sig, "SITE_NO"]))` parameters).

## Data preparation

The following data preparation steps were applied:

- Data from 2004 and later were used (due to changes in detection limits/instrumentation)
- Extreme outliers (> 10 Standard Deviations from the mean) were removed.
- Multiple readings from the same day were averaged (this was rare; only `r sum(bc_tidy$n > 1)` out of `r nrow(bc_tidy)` records had more than one daily reading)
- Values were aggregated to monthly medians; censored values were replaced with the detection limit. Literature suggests that this is not optimal as it biases any measure of central tendency upward (as the true value is less than the DL).  However, median is more robust to this bias than the mean. I intend to investigate better ways to treat censored data. When there were multiple readings in a month with different detection limits, only the records with the lowest detection limit were used.
- Full records were created (one record for every month of every year of the time series). 
- Only used records that were longer than 10 years and had readings up until at least 2014.
- Records were not adjusted for river flow/levels. This decision was made so that we are reporting on real concentrations of water quality parameters, not on why they might be changing. This is in keeping with SoE's mandate of reporting on _what_ is happening, not necessarily delving into the _why_.

### Data Preparation processes still under way:

- Trim ends of time series when they are very sparse (E.g., Sulphate at 'Englishman River at Hwy 19').
- Assess outliers
- Confirm censored data approach

## Trend analysis
- For each parameter at each station, we performed a Seasonal Kendall test with Sen slope estimator using the `kendallSeasonalTrendTest` function in the [`EnvStats` R package](https://cran.r-project.org/package=EnvStats). This performs a separate Mann Kendall for each month, and reports the median of all monthly Sen's slopes. The significance of the Seasonal Kendall is assessed using the overall Sk statistic, which is calculated by summing each season's Kendall S statistic.

```{r results='asis'}
station_results <- bc_nested %>%
  select(SITE_NO, PARAM_SHORT_NAME, 
         sk, slope_p_val, sig, annual_slope, ann_percent_change, intercept) %>% 
  nest(-SITE_NO, .key = "results")

i <- 1
for (s in station_results$SITE_NO) {
  d <- bc_nested %>% filter(SITE_NO == s) %>% 
    select(SITE_NO, PARAM_SHORT_NAME, Category, full_monthly) %>% 
    unnest() %>% 
    mutate(censored = case_when(censored ~ "censored", 
                                TRUE ~ "not censored"))
  
  res <- station_results %>% 
    filter(SITE_NO == s) %>% 
    unnest() %>% 
    left_join(group_by(d, SITE_NO, PARAM_SHORT_NAME) %>% 
                filter(!is.na(month_avg)) %>% 
                arrange(Date) %>% 
                summarize(max_val = max(month_avg), 
                          min_val = min(month_avg),
                          last_val = last(month_avg), 
                          label_y = scales::expand_range(range(month_avg), 0.3)[2]),
                            # ifelse(
                            # abs(max_val - last_val) > abs(min_val - last_val), 
                            # max_val, min_val)), 
              by = c("SITE_NO", "PARAM_SHORT_NAME")) %>% 
    mutate(slope_disp = ifelse(sig, 
                               format(round(ann_percent_change, digits = 1), 
                                      nsmall = 1), 
                               ""))
  
  site_name <- to_titlecase(bc_stations[bc_stations$SITE_NO == s, "SITE_NAME"])
  
  p <- ggplot(d, aes(x = Date, y = month_avg)) + 
    # geom_step(aes(y = detection_limit)) + 
    geom_point(size = 0.3, aes(alpha = censored), colour = "grey30") +
    scale_alpha_manual(values = c(0.4, 0.8)) + 
    scale_x_date(breaks = c(min(d$Date), max(d$Date)), 
                 date_minor_breaks = "2 years",
                 date_labels = "%Y") +
    geom_abline(
      data = res[res$sig, ], 
      aes(slope = annual_slope / 365, 
          intercept = intercept - 
            ((annual_slope / 365) * as.numeric(as.Date("2004-01-15"))), 
          colour = ifelse(sign(annual_slope) == 1, "Increasing", "Decreasing"))
    ) +
    geom_text(data = res[res$sig, ], x = max(d$Date), 
              aes(y = label_y, label = paste0(slope_disp, "%"), 
                  colour = ifelse(sign(annual_slope) == 1, 
                                  "Increasing", "Decreasing")), 
              vjust = 1, hjust = "inward", size = 2, show.legend = FALSE) + 
    facet_wrap(vars(PARAM_SHORT_NAME), scales = "free_y", 
               labeller = label_wrap_gen(width = 15)) + 
    theme_minimal(base_size = 9) + 
    theme(strip.text = element_text(size = 6), 
          axis.text = element_text(size = 5)) + 
    labs(title = site_name, 
         subtitle = sprintf("Site No: %s", s), 
         caption = "Lines illustrating statistically significant trends are shown on each graph panel.\nsValues of significant trends (in average % per year) are given",
         x = "Date", y = "Value", 
         colour = "Direction of Trend", 
         alpha = "Censored")
  print(p)
  # Add newlines between every second chart so they aren't crunched together
  # when two to a page.
  # If first chart appears on its own page, use "if (i %% 2 == 0)", if first two charts 
  # appear one a single page, use "if (i %% 2 != 0)"
  if (i %% 2 != 0) {
    cat("\\newline")
    cat("\\newline")
  }
  i <- i + 1
  
}

## TODO: check heterogeneity of slopes. Chi-Sq statitstic reported in `EnvStats::kendallSeasonalTrendTest`
```

## Summary of data and results for each parameter at all sites:

```{r, results='asis'}
reporting_table <- left_join(
  bc_site_var_summary %>% 
    mutate(percent_censored = round((n_cens / n_obs) * 100, 1)) %>% 
    select(-n_cens), 
  bc_nested %>%
    select(SITE_NO, PARAM_SHORT_NAME, ann_percent_change, slope_p_val,
           n_outliers), 
  by = c("SITE_NO", "PARAM_SHORT_NAME")
) %>% 
  mutate(PARAM_SHORT_NAME = case_when(
           grepl("^HARDNESS", PARAM_SHORT_NAME) ~ "Hardness Total", 
           PARAM_SHORT_NAME == "PH" ~ "pH",
           TRUE ~ to_titlecase(PARAM_SHORT_NAME)
         ),
         ann_percent_change = round(ann_percent_change, 2), 
         slope_p_val = round(slope_p_val, 3), 
         Years = paste(min_year, max_year, sep = "-"))

split_tbl <- split(reporting_table, reporting_table$SITE_NO)

for (i in seq_along(split_tbl)) {
  .x <- split_tbl[[i]]
  if (!nrow(.x)) break()
  
  .y <- names(split_tbl)[i]
  
  site_name <- to_titlecase(bc_stations[bc_stations$SITE_NO == .y, "SITE_NAME"])
  
  .x %>% 
    select(Category, PARAM_SHORT_NAME, Years, n_obs, percent_censored, 
           n_outliers, ann_percent_change, slope_p_val) %>% 
    kable(booktabs = TRUE, longtable = TRUE, 
          caption = paste0(site_name, " (", .y, ")"), 
          col.names = c("Category", "Parameter", "Years", "N", 
                        "\\% Censored", "Outliers", "Annual \\% $\\Delta$",
                        "p-value"), 
          # Use esacape=F and manually escape special characters to make 
          # greek letter Delta work
          escape = FALSE) %>% 
    kable_styling(latex_options = c("striped", "repeat_header")) %>% 
    print()
}

```

